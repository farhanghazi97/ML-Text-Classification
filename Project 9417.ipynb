{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dollar</th>\n",
       "      <th>won</th>\n",
       "      <th>bank</th>\n",
       "      <th>deal</th>\n",
       "      <th>clos</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>cent</th>\n",
       "      <th>foreign</th>\n",
       "      <th>suppl</th>\n",
       "      <th>move</th>\n",
       "      <th>...</th>\n",
       "      <th>morandin</th>\n",
       "      <th>mandy</th>\n",
       "      <th>mondes</th>\n",
       "      <th>hundley</th>\n",
       "      <th>alfonz</th>\n",
       "      <th>bankoa</th>\n",
       "      <th>caja</th>\n",
       "      <th>cooperativ</th>\n",
       "      <th>matthey</th>\n",
       "      <th>topic_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MONEY MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEFENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9496</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9497</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IRRELEVANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FOREX MARKETS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9500 rows Ã— 36948 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dollar  won  bank  deal  clos  wednesday  cent  foreign  suppl  move  \\\n",
       "0        8.0  5.0   5.0   4.0   3.0        3.0   3.0      2.0    2.0   2.0   \n",
       "1        2.0  0.0   1.0   3.0   2.0        0.0   0.0      0.0    0.0   0.0   \n",
       "2        0.0  0.0   0.0   0.0   0.0        2.0   0.0      0.0    0.0   1.0   \n",
       "3        4.0  0.0   2.0   1.0   0.0        0.0   2.0      0.0    0.0   0.0   \n",
       "4        0.0  0.0   0.0   0.0   1.0        0.0   0.0      0.0    0.0   0.0   \n",
       "...      ...  ...   ...   ...   ...        ...   ...      ...    ...   ...   \n",
       "9495     0.0  0.0   0.0   0.0   0.0        3.0   0.0      0.0    1.0   2.0   \n",
       "9496     2.0  0.0   0.0   0.0   1.0        0.0   0.0      4.0    0.0   0.0   \n",
       "9497     2.0  0.0   0.0   0.0   0.0        0.0   0.0      0.0    0.0   0.0   \n",
       "9498     0.0  0.0   0.0   0.0   0.0        0.0   0.0      0.0    0.0   0.0   \n",
       "9499     0.0  0.0   1.0   0.0   0.0        1.0   0.0      0.0    0.0   2.0   \n",
       "\n",
       "      ...  morandin  mandy  mondes  hundley  alfonz  bankoa  caja  cooperativ  \\\n",
       "0     ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "1     ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "2     ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "3     ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "4     ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "...   ...       ...    ...     ...      ...     ...     ...   ...         ...   \n",
       "9495  ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "9496  ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "9497  ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "9498  ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "9499  ...       0.0    0.0     0.0      0.0     0.0     0.0   0.0         0.0   \n",
       "\n",
       "      matthey   topic_target  \n",
       "0         0.0  FOREX MARKETS  \n",
       "1         0.0  MONEY MARKETS  \n",
       "2         0.0         SPORTS  \n",
       "3         0.0  FOREX MARKETS  \n",
       "4         0.0     IRRELEVANT  \n",
       "...       ...            ...  \n",
       "9495      0.0        DEFENCE  \n",
       "9496      0.0     IRRELEVANT  \n",
       "9497      0.0  FOREX MARKETS  \n",
       "9498      0.0     IRRELEVANT  \n",
       "9499      0.0  FOREX MARKETS  \n",
       "\n",
       "[9500 rows x 36948 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.95390266\n",
      "Iteration 2, loss = 1.29809898\n",
      "Iteration 3, loss = 1.11016456\n",
      "Iteration 4, loss = 0.99049937\n",
      "Iteration 5, loss = 0.90420571\n",
      "Iteration 6, loss = 0.84010865\n",
      "Iteration 7, loss = 0.79031684\n",
      "Iteration 8, loss = 0.75127514\n",
      "Iteration 9, loss = 0.71961362\n",
      "Iteration 10, loss = 0.69332726\n",
      "Iteration 11, loss = 0.67023850\n",
      "Iteration 12, loss = 0.65049385\n",
      "Iteration 13, loss = 0.63221546\n",
      "Iteration 14, loss = 0.61594373\n",
      "Iteration 15, loss = 0.60105817\n",
      "Iteration 16, loss = 0.58699779\n",
      "Iteration 17, loss = 0.57363634\n",
      "Iteration 18, loss = 0.56170467\n",
      "Iteration 19, loss = 0.54987216\n",
      "Iteration 20, loss = 0.53922810\n",
      "Iteration 21, loss = 0.52889175\n",
      "Iteration 22, loss = 0.51895346\n",
      "Iteration 23, loss = 0.50941697\n",
      "Iteration 24, loss = 0.49989967\n",
      "Iteration 25, loss = 0.49162475\n",
      "Iteration 26, loss = 0.48306071\n",
      "Iteration 27, loss = 0.47504293\n",
      "Iteration 28, loss = 0.46684866\n",
      "Iteration 29, loss = 0.45934225\n",
      "Iteration 30, loss = 0.45220950\n",
      "Iteration 31, loss = 0.44485427\n",
      "Iteration 32, loss = 0.43839196\n",
      "Iteration 33, loss = 0.43170128\n",
      "Iteration 34, loss = 0.42500998\n",
      "Iteration 35, loss = 0.41856171\n",
      "Iteration 36, loss = 0.41252103\n",
      "Iteration 37, loss = 0.40653099\n",
      "Iteration 38, loss = 0.40046593\n",
      "Iteration 39, loss = 0.39483637\n",
      "Iteration 40, loss = 0.38943531\n",
      "Iteration 41, loss = 0.38420680\n",
      "Iteration 42, loss = 0.37835806\n",
      "Iteration 43, loss = 0.37380938\n",
      "Iteration 44, loss = 0.36800019\n",
      "Iteration 45, loss = 0.36315331\n",
      "Iteration 46, loss = 0.35836749\n",
      "Iteration 47, loss = 0.35369436\n",
      "Iteration 48, loss = 0.34884440\n",
      "Iteration 49, loss = 0.34451876\n",
      "Iteration 50, loss = 0.33984898\n",
      "Iteration 51, loss = 0.33498057\n",
      "Iteration 52, loss = 0.33128405\n",
      "Iteration 53, loss = 0.32683336\n",
      "Iteration 54, loss = 0.32266206\n",
      "Iteration 55, loss = 0.31906954\n",
      "Iteration 56, loss = 0.31485686\n",
      "Iteration 57, loss = 0.31064360\n",
      "Iteration 58, loss = 0.30738750\n",
      "Iteration 59, loss = 0.30332087\n",
      "Iteration 60, loss = 0.29923692\n",
      "Iteration 61, loss = 0.29627349\n",
      "Iteration 62, loss = 0.29278869\n",
      "Iteration 63, loss = 0.28892759\n",
      "Iteration 64, loss = 0.28554604\n",
      "Iteration 65, loss = 0.28273173\n",
      "Iteration 66, loss = 0.27908097\n",
      "Iteration 67, loss = 0.27621211\n",
      "Iteration 68, loss = 0.27323079\n",
      "Iteration 69, loss = 0.27010570\n",
      "Iteration 70, loss = 0.26669255\n",
      "Iteration 71, loss = 0.26390664\n",
      "Iteration 72, loss = 0.26131902\n",
      "Iteration 73, loss = 0.25822379\n",
      "Iteration 74, loss = 0.25591804\n",
      "Iteration 75, loss = 0.25263341\n",
      "Iteration 76, loss = 0.24994541\n",
      "Iteration 77, loss = 0.24784900\n",
      "Iteration 78, loss = 0.24482952\n",
      "Iteration 79, loss = 0.24259309\n",
      "Iteration 80, loss = 0.24064915\n",
      "Iteration 81, loss = 0.23786103\n",
      "Iteration 82, loss = 0.23495381\n",
      "Iteration 83, loss = 0.23311292\n",
      "Iteration 84, loss = 0.23036167\n",
      "Iteration 85, loss = 0.22840288\n",
      "Iteration 86, loss = 0.22645944\n",
      "Iteration 87, loss = 0.22403476\n",
      "Iteration 88, loss = 0.22217243\n",
      "Iteration 89, loss = 0.21969285\n",
      "Iteration 90, loss = 0.21797691\n",
      "Iteration 91, loss = 0.21567754\n",
      "Iteration 92, loss = 0.21359848\n",
      "Iteration 93, loss = 0.21235215\n",
      "Iteration 94, loss = 0.21040713\n",
      "Iteration 95, loss = 0.20799252\n",
      "Iteration 96, loss = 0.20680097\n",
      "Iteration 97, loss = 0.20481983\n",
      "Iteration 98, loss = 0.20278095\n",
      "Iteration 99, loss = 0.20157256\n",
      "Iteration 100, loss = 0.19972866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0],\n",
       "       [  4,   2,   1,   0,   0,   0,   8,   0,   0,   0,   0],\n",
       "       [  0,   0,   8,   0,   0,   0,   4,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  20,   0,   4,  24,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  10,   2,   0,   2,   0,   0],\n",
       "       [  0,   1,   3,   1,   3,   4, 228,  20,   0,   2,   4],\n",
       "       [  0,   0,   0,   0,  18,   0,   9,  42,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,   0,   3,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   5,   0,   0,   0,  55]],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLPClassifier : 0.744\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                      IRRELEVANT       0.29      0.67      0.40         3\n",
      "                   MONEY MARKETS       0.67      0.13      0.22        15\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.67      0.62      0.64        13\n",
      "      ARTS CULTURE ENTERTAINMENT       0.67      1.00      0.80         2\n",
      "          SCIENCE AND TECHNOLOGY       0.49      0.42      0.45        48\n",
      "                  SHARE LISTINGS       0.67      0.71      0.69        14\n",
      "                          SPORTS       0.86      0.86      0.86       266\n",
      "                          HEALTH       0.49      0.61      0.54        69\n",
      "                   FOREX MARKETS       0.00      0.00      0.00         3\n",
      "                DOMESTIC MARKETS       0.60      0.43      0.50         7\n",
      "                         DEFENCE       0.93      0.92      0.92        60\n",
      "\n",
      "                        accuracy                           0.74       500\n",
      "                       macro avg       0.57      0.58      0.55       500\n",
      "                    weighted avg       0.75      0.74      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import chain\n",
    "\n",
    "def load_dataset(csv_file):\n",
    "    #import the file and convert it into a dataframe\n",
    "    data = pd.read_csv(csv_file)\n",
    "    return data\n",
    "\n",
    "def unionise_train_test(train,test):\n",
    "    train['Categorise'] = 'Training'\n",
    "    test['Categorise'] = 'Test'\n",
    "    unionised_data = pd.concat([train,test],ignore_index=True)\n",
    "    display(unionised_data)\n",
    "    return unionised_data\n",
    "    \n",
    "\n",
    "def split_words(data):\n",
    "    res = data['article_words'].str.split(',').apply(pd.value_counts)\n",
    "    res = res.fillna(0)\n",
    "    #cols = [col for col in res.columns]\n",
    "    #display(cols)\n",
    "    return res\n",
    "\n",
    "def get_word_list(data):\n",
    "    #We will need to consider the most popular words. However this might mean it might not be applicable for some articles\n",
    "    counter = pd.Series(np.concatenate([x.split(',') for x in data['article_words']])).value_counts()\n",
    "    word_list = counter.index.tolist()\n",
    "    return word_list\n",
    "\n",
    "def get_popular_words(data):\n",
    "    #We will need to consider the most popular words. However this might mean it might not be applicable for some articles\n",
    "    counter = pd.Series(np.concatenate([x.split(',') for x in data['article_words']])).value_counts()[:10000]\n",
    "    word_list = counter.index.tolist()\n",
    "    return counter,word_list\n",
    "\n",
    "def combine_with_target(data_left, data_right):\n",
    "\n",
    "    merge_data = pd.merge(data_left, data_right, left_index=True, right_index=True)\n",
    "    del merge_data['article_words']\n",
    "    del merge_data['article_number']\n",
    "    merge_data.rename(columns={\"topic_x\": \"topic\", \"topic_y\": \"topic_target\"},inplace = True)\n",
    "    \n",
    "    return merge_data\n",
    "\n",
    "def split_training_set(unionised_set):\n",
    "    train = unionised_set[unionised_set['Categorise'] == 'Training']\n",
    "    test = unionised_set[unionised_set['Categorise'] == 'Test']\n",
    "    del train['Categorise']\n",
    "    del test['Categorise']\n",
    "    return train, test\n",
    "    \n",
    "def accuracy(confusion_matrix):\n",
    "    diagonal_sum = confusion_matrix.trace()\n",
    "    sum_of_all_elements = confusion_matrix.sum()\n",
    "    return diagonal_sum / sum_of_all_elements\n",
    "\n",
    "#def implement_pca(x_set):\n",
    "#    pca = PCA(.95)\n",
    "#    pca.fit(x_set)\n",
    "#    train_pca = pca.transform(train_img)\n",
    "#    display(train_pca)\n",
    "\n",
    "def min_max_normalisation(data,word_list):\n",
    "    for i in range(len(word_list)):\n",
    "        data[word_list[i]] = (data[word_list[i]] - data[word_list[i]].min())/(data[word_list[i]].max() - data[word_list[i]].min())\n",
    "        \n",
    "    return data\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def build_model(x_train,y_train,x_test,y_test):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=100, alpha=0.05,\n",
    "                     solver='sgd', verbose=10,  random_state=21,activation = 'tanh')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    display(cm)\n",
    "    print(\"Accuracy of MLPClassifier : \" + str(accuracy(cm)))\n",
    "    \n",
    "    pred_labels = list(set(y_test))\n",
    "    print(classification_report(y_test,y_pred, target_names=pred_labels))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ##Load up the training set and test set\n",
    "    #training = load_dataset('training.csv')\n",
    "    #test = load_dataset('test.csv')\n",
    "    #Unionise the dataset\n",
    "    #unionised_dataset = unionise_train_test(training,test)\n",
    "    ###get all words from the unionised dataset\n",
    "    #all_words = get_word_list(unionised_dataset)\n",
    "    #word_count_data = split_words(unionised_dataset)\n",
    "    #word_count_norm = min_max_normalisation(word_count_data,all_words)\n",
    "    ##Prepare the training set##\n",
    "    word_count, word_list = get_popular_words(training)\n",
    "    merged_data = combine_with_target(word_count_data,unionised_dataset) \n",
    "    training_set,test_set = split_training_set(merged_data)\n",
    "\n",
    "\n",
    "    y = training_set['topic_target']\n",
    "    x = training_set[word_list]\n",
    "    display(training_set)\n",
    "    x_test = test_set[word_list]\n",
    "    y_test = test_set['topic_target'] \n",
    "    \n",
    " \n",
    "    build_model(x,y,x_test,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
